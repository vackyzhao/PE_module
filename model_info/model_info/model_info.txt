==============================
Layer Name: serving_default_sequential_input:0
Layer Index: 0
Layer Shape: [ 1 24 32  1]
Layer Quantization Parameters: zero_point = [0], scale = [1.]
Weights: See weights_0.npy

==============================
Layer Name: sequential_1/flatten/Const
Layer Index: 1
Layer Shape: [2]
Layer Quantization Parameters: zero_point = [], scale = []
Weights: See weights_1.npy

==============================
Layer Name: sequential_1/dense/MatMul1
Layer Index: 2
Layer Shape: [ 27 384]
Layer Quantization Parameters: zero_point = [0], scale = [0.05203861]
Weights: See weights_2.npy

==============================
Layer Name: sequential_1/conv2d_1/Conv2D
Layer Index: 3
Layer Shape: [8]
Layer Quantization Parameters: zero_point = [0 0 0 0 0 0 0 0], scale = [0.00081839 0.00053756 0.00123009 0.00737761 0.00088787 0.0024281
 0.00088216 0.00259815]
Weights: See weights_3.npy

==============================
Layer Name: sequential_1/conv2d_1/Conv2D1
Layer Index: 4
Layer Shape: [8 3 3 4]
Layer Quantization Parameters: zero_point = [0 0 0 0 0 0 0 0], scale = [0.00349254 0.00229409 0.00524954 0.03148467 0.00378907 0.01036217
 0.00376472 0.01108783]
Weights: See weights_4.npy

==============================
Layer Name: sequential_1/conv2d/Conv2D
Layer Index: 5
Layer Shape: [4]
Layer Quantization Parameters: zero_point = [0 0 0 0], scale = [0.00283895 0.00060151 0.00108942 0.00074077]
Weights: See weights_5.npy

==============================
Layer Name: sequential_1/conv2d/Conv2D1
Layer Index: 6
Layer Shape: [4 3 3 1]
Layer Quantization Parameters: zero_point = [0 0 0 0], scale = [0.00283895 0.00060151 0.00108942 0.00074077]
Weights: See weights_6.npy

==============================
Layer Name: tfl.quantize
Layer Index: 7
Layer Shape: [ 1 24 32  1]
Layer Quantization Parameters: zero_point = [-128], scale = [1.]
Weights: See weights_7.npy

==============================
Layer Name: sequential_1/re_lu/Relu;sequential_1/conv2d/Conv2D
Layer Index: 8
Layer Shape: [ 1 24 32  4]
Layer Quantization Parameters: zero_point = [-128], scale = [0.23432396]
Failed to get weights for layer sequential_1/re_lu/Relu;sequential_1/conv2d/Conv2D: Tensor data is null. Run allocate_tensors() first

==============================
Layer Name: sequential_1/max_pooling2d/MaxPool
Layer Index: 9
Layer Shape: [ 1 12 16  4]
Layer Quantization Parameters: zero_point = [-128], scale = [0.23432396]
Failed to get weights for layer sequential_1/max_pooling2d/MaxPool: Tensor data is null. Run allocate_tensors() first

==============================
Layer Name: sequential_1/re_lu_1/Relu;sequential_1/conv2d_1/Conv2D
Layer Index: 10
Layer Shape: [ 1 12 16  8]
Layer Quantization Parameters: zero_point = [-128], scale = [0.10555632]
Failed to get weights for layer sequential_1/re_lu_1/Relu;sequential_1/conv2d_1/Conv2D: Tensor data is null. Run allocate_tensors() first

==============================
Layer Name: sequential_1/max_pooling2d_1/MaxPool
Layer Index: 11
Layer Shape: [1 6 8 8]
Layer Quantization Parameters: zero_point = [-128], scale = [0.10555632]
Failed to get weights for layer sequential_1/max_pooling2d_1/MaxPool: Tensor data is null. Run allocate_tensors() first

==============================
Layer Name: sequential_1/flatten/Reshape
Layer Index: 12
Layer Shape: [  1 384]
Layer Quantization Parameters: zero_point = [-128], scale = [0.10555632]
Failed to get weights for layer sequential_1/flatten/Reshape: Tensor data is null. Run allocate_tensors() first

==============================
Layer Name: StatefulPartitionedCall:01
Layer Index: 13
Layer Shape: [ 1 27]
Layer Quantization Parameters: zero_point = [79], scale = [1.1237617]
Weights: See weights_13.npy

==============================
Layer Name: StatefulPartitionedCall:0
Layer Index: 14
Layer Shape: [ 1 27]
Layer Quantization Parameters: zero_point = [207], scale = [1.1237617]
Weights: See weights_14.npy

==============================
Layer Name: 
Layer Index: 21
Layer Shape: [ 1 24 32  9]
Layer Quantization Parameters: zero_point = [], scale = []
Weights: See weights_21.npy

==============================
Layer Name: 
Layer Index: 22
Layer Shape: [ 1 12 16 36]
Layer Quantization Parameters: zero_point = [], scale = []
Weights: See weights_22.npy

